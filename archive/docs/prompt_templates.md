I’m returning to a Python/ML project that I haven't touched in a while and I don’t fully remember how everything works.  

I’ll upload the relevant source files, data files, and markdown documentation.  

Please do the following:

1. **Scan the folder structure and code** to identify:
    - What the project does overall
    - What each script is for
    - Which scripts are core vs. unused or legacy

2. **Reconstruct the end-to-end pipeline flow**, including:
    - Data inputs (e.g., what kind of data it processes)
    - Main steps (e.g., training, prediction, feedback loop)
    - Output artifacts (e.g., models, logs, predictions)

3. **Summarize my current setup**, including:
    - Key directories (e.g., `src`, `models`, `data`)
    - Critical files or modules
    - Any outdated folders I might want to archive or delete

4. **Check my documentation files** and tell me:
    - Which ones are outdated or redundant
    - What should be merged, rewritten, or removed

5. Suggest how I can:
    - Clean up my folder structure
    - Update my `README.md` or create a `docs/` folder
    - Embed a visual diagram of the pipeline if helpful

Assume I retrain my model each cycle and work with two transaction sources: household and credit card.  
You can ask me follow-up questions if needed, but try to infer as much as you can from the files I upload.